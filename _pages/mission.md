---
layout: splash
title: "Mission"
permalink: /mission/
collection: mission
header:
  overlay_color: "#5e616c"
  overlay_image: /assets/images/neuro-mission.png
feature_row:
  - title: "The Problem"
    excerpt: |
      Acquiring neurophysiology data is expensive and time-consuming, often involving highly skilled individuals and the use of animals. As scientists, it is our duty to ensure that this data is utilized to its maximum potential. We understand that data collected for one project could be used to answer additional scientific queries, but sharing this data can be quite difficult.

      Data can be stored in many different formats, and important metadata required for analysis could be missing or stored in ways that are hard to share. Software developed in labs can also be difficult to distribute, mainly due to the need for converting obscure data formats and a lack of adequate documentation and user-friendly packaging. As a result, labs often collect entirely new data and create new software instead of collaborating.

      This situation has a significant impact on the neuroscience community and hinders scientific progress. Not sharing data leads to wasted time, money, and underuse of animal subjects. It also makes it harder to verify existing studies and to conduct follow-up research. In-depth analyses across multiple labs are very labor-intensive, and the effort put into software development usually only benefits a few researchers.

      A key reason for this issue is that it can be difficult for research labs to devote the necessary time and attention to data and software engineering. Pushing the boundaries of human knowledge requires enormous effort, and most research groups work within a “publish-or-perish” system where labs that focus on looking for the next big scientific findings will supplant labs that divert attention to other things. In addition, until recently, there has not been strong consensus in the field around data standards or processing pipelines.

      The problem has become more urgent recently, with a new NIH policy that all papers must include the publication of scientific data. Now, whether motivated by an appreciation for open science or by funding requirements, many labs are facing new challenges in sharing data. This problem is exacerbated by new data acquisition technologies that are producing data at an unprecedented pace.

    image_path: /assets/images/neuroconv_logo.png
feature_row2:
  - title: "Our Solution"
    excerpt: NeuroConv provides automated conversions from proprietary formats
    image_path: /assets/images/neuroconv_logo.png
---

{% include feature_row type="left" %}
{% include feature_row id="feature_row2" type="left" %}